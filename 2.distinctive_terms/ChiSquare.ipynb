{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T00:03:04.763725Z",
     "start_time": "2020-07-15T00:03:04.087467Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import nltk\n",
    "import operator\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T00:03:17.471114Z",
     "start_time": "2020-07-15T00:03:17.466870Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_tweets_from_json(filename):\n",
    "    tweets=[]\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        data=json.load(file)\n",
    "        for tweet in data:\n",
    "            tweets.append(tweet[\"text\"])\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T00:03:20.180806Z",
     "start_time": "2020-07-15T00:03:19.995818Z"
    }
   },
   "outputs": [],
   "source": [
    "trump_tweets=read_tweets_from_json(\"../data/trump_tweets.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T00:03:21.607681Z",
     "start_time": "2020-07-15T00:03:21.361205Z"
    }
   },
   "outputs": [],
   "source": [
    "aoc_tweets=read_tweets_from_json(\"../data/aoc_tweets.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore your assumptions between the words you think will most distinguish the tweets of Donald Trump from those Alexandria Ocasio-Cortez.  Before looking at the data, what words do you think will be comparatively distinct to both?  (If you're not familiar with either, see http://twitter.com/realDonaldTrump and http://twitter.com/AOC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T00:07:51.859341Z",
     "start_time": "2020-07-15T00:07:51.853357Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_tweets_to_tokens(tweets):\n",
    "    tokens=[]\n",
    "    for tweet in tweets:\n",
    "        tokens.extend(nltk.casual_tokenize(tweet))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T00:08:10.454656Z",
     "start_time": "2020-07-15T00:08:10.451148Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_counts(tokens):\n",
    "    counts=Counter()\n",
    "    for token in tokens:\n",
    "        counts[token]+=1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\chi^2$ test as used in the comparison of different texts is designed to measure how statistically significant the distriubtion of counts in a 2x2 contingency table is.  Use the following function to analyze the difference between these accounts.  How do the most distinct terms comport with your assumptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T00:15:17.986089Z",
     "start_time": "2020-07-15T00:15:17.976116Z"
    }
   },
   "outputs": [],
   "source": [
    "def chi_square(one_counts, two_counts):\n",
    "\n",
    "    one_sum=0.\n",
    "    two_sum=0.\n",
    "    vocab={}\n",
    "    for word in one_counts:\n",
    "        one_sum+=one_counts[word]\n",
    "        vocab[word]=1\n",
    "    for word in two_counts:\n",
    "        vocab[word]=1\n",
    "        two_sum+=two_counts[word]\n",
    "\n",
    "    N=one_sum+two_sum\n",
    "    vals={}\n",
    "    \n",
    "    for word in vocab:\n",
    "        O11=one_counts[word]\n",
    "        O12=two_counts[word]\n",
    "        O21=one_sum-one_counts[word]\n",
    "        O22=two_sum-two_counts[word]\n",
    "        \n",
    "        # We'll use the simpler form given in Manning and Schuetze (1999) \n",
    "        # for 2x2 contingency tables: \n",
    "        # https://nlp.stanford.edu/fsnlp/promo/colloc.pdf, equation 5.7\n",
    "        \n",
    "        vals[word]=(N*(O11*O22 - O12*O21)**2)/((O11 + O12)*(O11+O21)*(O12+O22)*(O21+O22))\n",
    "        \n",
    "    sorted_chi = sorted(vals.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    one=[]\n",
    "    two=[]\n",
    "    for k,v in sorted_chi:\n",
    "        if one_counts[k]/one_sum > two_counts[k]/two_sum:\n",
    "            one.append(k)\n",
    "        else:\n",
    "            two.append(k)\n",
    "    \n",
    "    print (\"@realdonaldtrump:\\n\")\n",
    "    for k in one[:20]:\n",
    "        print(\"%s\\t%s\" % (k,vals[k]))\n",
    "\n",
    "    print (\"\\n\\n@AOC:\\n\")\n",
    "    for k in two[:20]:\n",
    "        print(\"%s\\t%s\" % (k,vals[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T00:15:33.812956Z",
     "start_time": "2020-07-15T00:15:30.762049Z"
    }
   },
   "outputs": [],
   "source": [
    "trump_tokens=convert_tweets_to_tokens(trump_tweets)\n",
    "trump_counts=get_counts(trump_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T00:15:34.355074Z",
     "start_time": "2020-07-15T00:15:34.037751Z"
    }
   },
   "outputs": [],
   "source": [
    "aoc_tokens=convert_tweets_to_tokens(aoc_tweets)\n",
    "aoc_counts=get_counts(aoc_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T00:15:39.091207Z",
     "start_time": "2020-07-15T00:15:38.900676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@realdonaldtrump:\n",
      "\n",
      "\"\t1843.3462598546037\n",
      "@realDonaldTrump\t767.7537107486318\n",
      "!\t735.1458768455142\n",
      ".\t390.8452989655345\n",
      "Trump\t308.2324244351674\n",
      "will\t226.22255210586596\n",
      "great\t206.309973781387\n",
      "Donald\t139.34687488005184\n",
      "Obama\t122.4401090728926\n",
      "Thanks\t118.68753314790392\n",
      "be\t108.05517114062634\n",
      "...\t106.28152288766938\n",
      "Great\t103.51347969059988\n",
      "he\t101.40623092074443\n",
      "President\t79.85272402251856\n",
      "#Trump2016\t74.21019140598298\n",
      "president\t71.74551195557245\n",
      "?\t71.28235249685538\n",
      "his\t69.37430185956471\n",
      "U\t68.78604706272642\n",
      "\n",
      "\n",
      "@AOC:\n",
      "\n",
      "‚Ä¶\t15795.91275829964\n",
      "@Ocasio2018\t6518.920393680039\n",
      "RT\t5536.225035994314\n",
      "üíú\t2091.116009234117\n",
      "‚Äô\t1632.664834479263\n",
      "üèΩ\t1459.8766408560216\n",
      "*\t989.3264413370716\n",
      "Queens\t947.1505645422372\n",
      "Bronx\t925.0762605949463\n",
      "+\t792.9379998245004\n",
      "Ocasio-Cortez\t747.8298934010594\n",
      "Alexandria\t712.0431240696781\n",
      "@AOC\t668.5093331893148\n",
      "Ô∏è\t615.1176007845903\n",
      "üí™\t607.8691457792726\n",
      "Ocasio\t600.5212766556089\n",
      "s\t523.3983763090894\n",
      "re\t522.0381636819615\n",
      "progressive\t508.1585138436886\n",
      "Crowley\t496.83364760794115\n"
     ]
    }
   ],
   "source": [
    "chi_square(trump_counts, aoc_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw earlier that $\\chi^2$ is not a perfect estimator since it doesn't account for the burstiness of language (the tendency of mentions of the same word to clump together in a text).  Do you expect this to still hold on Twitter?  Why or why not?  How are the differences identified by a $\\chi^2$ similar to those by Mann-Whitney?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
