{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores distribitional simliarity in a dataset of 10,000 Wikipedia articles (4.4M words), building high-dimensional, sparse representations for words from the distinct contexts they appear in.  These representations allow for analysis of the most similar words to a given query, and are interpretable with respect to the specific contexts that are most important for determining that two words are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T23:24:15.695317Z",
     "start_time": "2020-07-15T23:24:15.689359Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "import operator\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T23:24:15.706724Z",
     "start_time": "2020-07-15T23:24:15.698764Z"
    }
   },
   "outputs": [],
   "source": [
    "window=2\n",
    "vocabSize=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T23:24:16.335063Z",
     "start_time": "2020-07-15T23:24:15.709707Z"
    }
   },
   "outputs": [],
   "source": [
    "filename=\"../data/wiki.10K.txt\"\n",
    "\n",
    "wiki_data=open(filename, encoding=\"utf-8\").read().lower().split(\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T23:25:07.359955Z",
     "start_time": "2020-07-15T23:25:07.352977Z"
    }
   },
   "outputs": [],
   "source": [
    "# We'll only create word representation for the most frequent K words\n",
    "\n",
    "def create_vocab(data):\n",
    "    word_representations={}\n",
    "    vocab=Counter()\n",
    "    for i, word in enumerate(data):\n",
    "        vocab[word]+=1\n",
    "\n",
    "    topK=[k for k,v in vocab.most_common(vocabSize)]\n",
    "    for k in topK:\n",
    "        word_representations[k]=defaultdict(float)\n",
    "    return word_representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T23:26:09.066688Z",
     "start_time": "2020-07-15T23:26:09.061699Z"
    }
   },
   "outputs": [],
   "source": [
    "# word representation for a word = its unigram distributional context (the unigrams that show\n",
    "# up in a window before and after its occurence)\n",
    "\n",
    "def count_unigram_context(data, word_representations):\n",
    "    for i, word in enumerate(data):\n",
    "        if word not in word_representations:\n",
    "            continue\n",
    "        start=i-window if i-window > 0 else 0\n",
    "        end=i+window+1 if i+window+1 < len(data) else len(data)\n",
    "        for j in range(start, end):\n",
    "            if i != j:\n",
    "                word_representations[word][data[j]]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T23:26:13.743955Z",
     "start_time": "2020-07-15T23:26:13.735981Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_directional_context(data, word_representations):\n",
    "    for i, word in enumerate(data):\n",
    "        if word not in word_representations:\n",
    "            continue\n",
    "        start=i-window if i-window > 0 else 0\n",
    "        end=i+window+1 if i+window+1 < len(data) else len(data)\n",
    "        left=\"L: %s\" % ' '.join(data[start:i])\n",
    "        right=\"R: %s\" % ' '.join(data[i+1:end])\n",
    "        \n",
    "        word_representations[word][left]+=1\n",
    "        word_representations[word][right]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T23:26:26.480517Z",
     "start_time": "2020-07-15T23:26:26.474405Z"
    }
   },
   "outputs": [],
   "source": [
    "# normalize a word represenatation vector that its L2 norm is 1.\n",
    "# we do this so that the cosine similarity reduces to a simple dot product\n",
    "\n",
    "def normalize(word_representations):\n",
    "    for word in word_representations:\n",
    "        total=0\n",
    "        for key in word_representations[word]:\n",
    "            total+=word_representations[word][key]*word_representations[word][key]\n",
    "            \n",
    "        total=math.sqrt(total)\n",
    "        for key in word_representations[word]:\n",
    "            word_representations[word][key]/=total\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T23:27:37.124829Z",
     "start_time": "2020-07-15T23:27:37.119732Z"
    }
   },
   "outputs": [],
   "source": [
    "def dictionary_dot_product(dict1, dict2):\n",
    "    dot=0\n",
    "    for key in dict1:\n",
    "        if key in dict2:\n",
    "            dot+=dict1[key]*dict2[key]\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T23:27:47.609120Z",
     "start_time": "2020-07-15T23:27:47.604703Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_sim(word_representations, query):\n",
    "    if query not in word_representations:\n",
    "        print(\"'%s' is not in vocabulary\" % query)\n",
    "        return None\n",
    "    \n",
    "    scores={}\n",
    "    for word in word_representations:\n",
    "        cosine=dictionary_dot_product(word_representations[query], word_representations[word])\n",
    "        scores[word]=cosine\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T23:27:55.968593Z",
     "start_time": "2020-07-15T23:27:55.963532Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find the K words with highest cosine similarity to a query in a set of word_representations\n",
    "def find_nearest_neighbors(word_representations, query, K):\n",
    "    scores=find_sim(word_representations, query)\n",
    "    if scores != None:\n",
    "        sorted_x = sorted(scores.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        for idx, (k, v) in enumerate(sorted_x[:K]):\n",
    "            print(\"%s\\t%s\\t%.5f\" % (idx,k,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the difference between `count_unigram_context` and `count_directional_context` for determining what counts as \"context\".  `count_unigram_context` counts an individual unigram in the bag of words around a target as a \"context\" variable, while `count_directional_context` counts the sequence of words before and after the word as a single \"context\"--and specifies the direction it occurs (to the left or right of the word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T23:28:40.650988Z",
     "start_time": "2020-07-15T23:28:28.901703Z"
    }
   },
   "outputs": [],
   "source": [
    "word_representations=create_vocab(wiki_data)\n",
    "count_unigram_context(wiki_data, word_representations)\n",
    "normalize(word_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T23:29:00.752773Z",
     "start_time": "2020-07-15T23:29:00.421063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tactor\t1.00000\n",
      "1\tactress\t0.94363\n",
      "2\tartist\t0.88560\n",
      "3\twriter\t0.85602\n",
      "4\tpolitician\t0.84846\n",
      "5\tmusician\t0.84787\n",
      "6\tentrepreneur\t0.84640\n",
      "7\tengineer\t0.83586\n",
      "8\tsinger\t0.82831\n",
      "9\tactivist\t0.82257\n"
     ]
    }
   ],
   "source": [
    "find_nearest_neighbors(word_representations, \"actor\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T23:29:51.619451Z",
     "start_time": "2020-07-15T23:29:51.612470Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's find the contexts shared between two words that have the most contribution\n",
    "# to the cosine similarity\n",
    "\n",
    "def find_shared_contexts(word_representations, query1, query2, K):\n",
    "    if query1 not in word_representations:\n",
    "        print(\"'%s' is not in vocabulary\" % query1)\n",
    "        return None\n",
    "    \n",
    "    if query2 not in word_representations:\n",
    "        print(\"'%s' is not in vocabulary\" % query2)\n",
    "        return None\n",
    "    \n",
    "    context_scores={}\n",
    "    dict1=word_representations[query1]\n",
    "    dict2=word_representations[query2]\n",
    "    \n",
    "    for key in dict1:\n",
    "        if key in dict2:\n",
    "            score=dict1[key]*dict2[key]\n",
    "            context_scores[key]=score\n",
    "\n",
    "    sorted_x = sorted(context_scores.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for idx, (k, v) in enumerate(sorted_x[:K]):\n",
    "        print(\"%s\\t%s\\t%.5f\" % (idx,k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T23:29:55.185470Z",
     "start_time": "2020-07-15T23:29:55.180482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tand\t0.22555\n",
      "1\t.\t0.18242\n",
      "2\ta\t0.10453\n",
      "3\t,\t0.09911\n",
      "4\tan\t0.07981\n",
      "5\tthe\t0.05109\n",
      "6\the\t0.01720\n",
      "7\tin\t0.01608\n",
      "8\tamerican\t0.01511\n",
      "9\t(\t0.01307\n"
     ]
    }
   ],
   "source": [
    "find_shared_contexts(word_representations, \"actor\", \"politician\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
